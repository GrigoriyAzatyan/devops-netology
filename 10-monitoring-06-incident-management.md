# Постмортем сбоя системы Github в 2018 году

## Краткое описание инцидента 
22 октября 2018 г. cо слов пользователй обнаружилось, что при попытке создания Issue и записи комментариев к уже существующим — запись/комментарий визуально отображаются а после перезагрузки — пропадают. 
По информации GitHub, в течение инцидента внешний веб-сервис отображал устаревшую и непоследовательную информацию, однако в реальности никакие пользовательские данные не были потеряны. В большинстве случаев GitHub также не мог обслуживать события webhook или создавать и публиковать сайты GitHub Pages."

## Предшествующие события 
21 октября 2018 г. в 22:52 по UTC на нескольких сервисах GitHub.com пострадали несколько сетевых разделов и последующим сбоем базы данных. 

## Причина инцидента 
Плановая замна сетевого оборудования и последующая потеря сетевого соединения между сетевым узлом и основным ЦОД на Восточном побережье США на 43 секунды вызвали перестроение распределенного кластера СУБД, что повлекло несогласованность данных между изолированными друг от друга частями кластера СУБД.

## Воздействие 
Инцидент вызвал ухудшение качества обслуживания, в частности отображение устаревших данных в пользовательском веб-интерфейсе и другие проблемы с работой сервиса и доступностью данных.

## Обнаружение 
Инцидент был замечен инженерами из группы быстрого реагирования. Позднее были вызваны дополнительные инженеры из команды разработчиков баз данных, которые подключились к решению проблемы.

## Реакция 
Окончательно инцидент был устранен в течение 24 часов и 11 минут.

## Восстановление 
Было выполнено восстановление баз данных из резервных копий и синхронизация реплик на обоих сайтах. Навсе время восстановления кластер был настроен на максимальную сохранность данных в ущерб производительности и качеству обслуживания.

## Таймлайн 

### 2018 October 21 22:52 UTC. 
Плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования 100G привели к потере связи между сетевым узлом на Восточном побережье США и  основным ЦОД на Восточном побережье США. Связь между этими местоположениями была восстановлена за 43 секунды, но это короткое отключение вызвало дальнейшую цепочку событий. После перестроения кластера серверы БД в ЦОД Восточного побережья США содержали часть записей, которые не были реплицированы на объект Западного побережья США. 

### 2018 October 21 22:54 UTC. 
Внутренние системы мониторинга начали генерировать предупреждения, указывающие на то, что в  системах происходят многочисленные сбои. К 23:02 UTC инженеры из группы быстрого реагирования определили, что топологии для многочисленных кластеров баз данных находятся в неожиданном состоянии. Запрос API Orchestrator отобразил топологию репликации базы данных, которая включала только серверы из ЦОД на Западном побережье США.

### 2018 October 21 23:07 UTC. 
К этому моменту отвечающая команда решила вручную заблокировать внутренний инструментарий развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. В 23:09 UTC группа реагирования присвоила сайту желтый статус. Это действие автоматически превратило ситуацию в активный инцидент и отправило предупреждение координатору инцидентов. В 23:11 UTC координатор инцидента присоединился и через две минуты принял решение изменить статус на красный.

### 2018 October 21 23:13 UTC. 
В то время стало понятно, что проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из команды разработчиков баз данных GitHub. К этому моменту кластер баз данных Западного побережья принимал записи с уровня приложений в течение почти 40 минут. Кроме того, в кластере Восточного побережья существовало несколько секунд записей, которые не были реплицированы на Западное побережье и препятствовали репликации новых записей обратно на Восточное побережье.
Стремясь сохранить пользовательские данные, было принято решение в пользу целостности данных, в ущерб их доступности. "

### 2018 October 21 23:19 UTC. 
Из запроса состояния кластеров базы данных стало ясно, что нужно остановить выполнение заданий, записывающих метаданные о таких вещах, как push-уведомления. 

### 2018 October 22 00:05 UTC. 
Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL. План состоял в том, чтобы восстановить из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. 

### 2018 October 22 00:41 UTC. 
К этому времени был инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры следили за его ходом. Одновременно несколько групп инженеров искали способы ускорить передачу и время восстановления без дальнейшего ухудшения удобства использования сайта или риска повреждения данных.

### 2018 October 22 06:51 UTC. 
Несколько кластеров завершили восстановление из резервных копий в  ЦОД на восточном побережье США и начали репликацию новых данных с западного побережья. Ожидаемое время восстановления составляло два часа.

### 2018 October 22 07:46 UTC. 
GitHub опубликовал сообщение в блоге с извинениями.

### 2018 October 22 11:12 UTC. 
Все первичные базы данных снова установлены на восточном побережье США. Это привело к тому, что сайт стал гораздо более отзывчивым, так как записи теперь направлялись на сервер баз данных, расположенный в том же ЦОД, что и уровень приложений. Несмотря на то, что это существенно повысило производительность, по-прежнему существовали десятки реплик чтения базы данных, которые отставали от основной на несколько часов. Эти отложенные реплики приводили к тому, что пользователи видели несогласованные данные при взаимодействии с нашими службами. Мы распределили нагрузку чтения по большому пулу реплик чтения, и каждый запрос к нашим службам имел хорошие шансы попасть в реплику чтения, которая задерживалась на несколько часов.

### 2018 October 22 13:15 UTC. 
К настоящему времени мы приближались к пиковой нагрузке трафика на GitHub.com. Группа реагирования на инциденты обсудила, как действовать дальше. Было ясно, что задержки репликации увеличиваются, а не уменьшаются. Мы начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке восточного побережья США ранее во время инцидента. Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. Сокращение совокупного использования реплик чтения позволило репликации наверстать упущенное.
2018 October 22 16:24 UTC.
Как только реплики были синхронизированы, было выполнено аварийное переключение на исходную топологию, что решило  проблемы с задержкой/доступностью.

### 2018 October 22 16:45 UTC. 
На этом этапе нужно было сбалансировать возросшую нагрузку, вызванную выросшей очередью невыполненных уведомлений и вебхуков. 
Когда мы повторно включили обработку этих данных, мы обработали около 200 000 полезных нагрузок веб-перехватчиков, которые пережили внутренний TTL и были удалены. Обнаружив это, мы приостановили эту обработку и внесли изменение, чтобы на время увеличить этот TTL.
Чтобы избежать дальнейшего подрыва надежности наших обновлений статуса, мы оставались в ухудшенном статусе до тех пор, пока не завершили обработку всего отставания данных и не убедились, что наши сервисы явно вернулись к нормальному уровню производительности."

### 2018 October 22 23:03 UTC. 
Все ожидающие вебхуки и страницы были обработаны, и была подтверждена целостность и правильная работа всех систем. Статус сайта был обновлен до зеленого.

## Последующие действия 
1. Настроили конфигурацию Orchestrator, чтобы предотвратить перемещение основных баз данных через региональные границы. 
2. Ускорили переход на новый механизм отчетов о состоянии, который предоставит нам большие возможности для обсуждения активных инцидентов.
3. За несколько недель до этого инцидента мы начали общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в схеме «активный/активный/активный». Целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. Это серьезное усилие, которое займет некоторое время, но мы считаем, что наличие нескольких сайтов с хорошей связью в одном регионе обеспечивает хороший набор компромиссов. Этот инцидент добавил актуальности инициативе.
4. Этот инцидент изменил наше отношение к надежности сайта. Мы узнали, что более строгий операционный контроль или сокращение времени отклика не являются достаточными гарантиями надежности сайта в рамках такой сложной системы услуг, как наша. Чтобы поддержать эти усилия, мы также начнем системную практику проверки сценариев сбоев, прежде чем они смогут повлиять на вас. Эта работа потребует будущих инвестиций в инструменты внедрения ошибок и хаос-инжиниринга в GitHub.



